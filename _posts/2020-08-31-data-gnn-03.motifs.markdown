---
layout: post
title:  "CS224W - 03.Motifs and Structural Roles in Networks"  
subtitle:   "GNN-03.Motifs and Structural Roles in Networks"
categories: data
tags: gnn
comments: true
---

- CS224W의 3주차 강의, Motifs and Structural Roles in Networks를 보고 정리한 글입니다.  

---  

### 부분그래프 (Subgraph = Subnetworks)  
- Network의 Building block  
  ![GNN03-1](https://user-images.githubusercontent.com/43376853/91663880-7c01d180-eb26-11ea-96af-c47cd8e65e33.png)  
- 부분그래프의 역할  
  1. `Characterize` the network  
  2. `Discriminate` the (types of) network  
  
  ```  
  Subnetworks have the power to characerize and discriminate networks.  
  ```  
  
- 예를 들어, 3개의 노드를 가진 Non-isomorphic한 모든 방향 그래프를 생각해보자.  
  -> 13개를 생각해볼 수 있음   
  ![GNN03-2](https://user-images.githubusercontent.com/43376853/91663958-ec105780-eb26-11ea-8744-57b02627b0fd.png)  

  - 이 때, 각 subgraph들에 대해, 이들의 `Significance`를 분류해볼 수 있는 metric은 없을까?  
    (Negative value를 지닌다면, under-representation으로 평가하고  
    positive value를 지닌다면, over-representation으로 평가하는)  
    ↓  
    #### Network Significance Profile  
    : 모든 Subgraph 타입들에 대한 값들(values)을 갖고 있는 feature vector  
    : 각 Subgraph들이 over-represented 되었는지, under-represented 되었는지를 보여줄 숫자.  
    - 단, domain이 다르면 network도 다르다.  
    
    ![GNN03-3](https://user-images.githubusercontent.com/43376853/91664258-faf80980-eb28-11ea-8131-827cfe5bd3e7.png)
      
      ```  
      1. 네 가지 plot들은 모두 다른 종류의 네트워크를 표현  
      2. 1번 Subgraph를 예로 들어 생각해보면,  
        Language netowrk에서는 over-represented 되어있으나  
        Web & Socail network에서는 under-represented 되어 있음.  
      3. 각 network 마다의 그래프는 모두 다르지만, 서로 행동 양태가 상당히 비슷함.  
      4. y-axis가 바로 significance profile  
      ```  
      
      - 4번에서, 'significance profile을 어떻게 generate 하는가?'에 대한 답은 아래의   
        ### Network Significance Profile (SP)   
        를 참조.  
        
---  

## Subgraphs, Motifs, and Graphlets  

### Network motifs  
:= "_Recurring_, _Significant_ _Patterns_ of interconnections". (하나의 정의로 생각하면 됨)  
  - `Pattern`: 작은 [Induced subgraph](https://en.wikipedia.org/wiki/Induced_subgraph)  
  - 'Recurring': 고빈도로, 자주 발견됨.  
  - `Significant`: 생각했던 것보다 더 Frequent  
     └-> 역시 그 비교기준이 필요하고 
      -> 그 기준으로 'Erdos-Renyi random graphs, scale-free networks'등을 사용  
     
### Motifs  
- 네트워크가 어떻게 작동하는지를 이해하는 데에 도움을 줌  
- 주어진 상황에서 연산(operation)과 반응(reaction)을 예측하는 데에 도움을 줌  

- 예시  
  ![GNN03-4](https://user-images.githubusercontent.com/43376853/91664859-d0a84b00-eb2c-11ea-945b-472a0956de7d.png)  
  - cf. Feed-forward loops: 딥러닝에서의 Skip connection  
  
### 위 Network Motifs에 대한 구체화  
- Induced Subgraph in `Pattern`  
  ![GNN03-5](https://user-images.githubusercontent.com/43376853/91664913-2e3c9780-eb2d-11ea-8959-4d27e648f068.png)  
- `Recurrence`  
  ![GNN03-6](https://user-images.githubusercontent.com/43376853/91665035-d5213380-eb2d-11ea-8db2-e90629226166.png)  
- `Significance` 
  - 아이디어: Random Network를 generate했을 때, 특정 Subgraph가 Real Network에서 훨씬 많이 나타난다면, 그 Subgraph는 functional significance를 갖고 있을 것!  
    ![GNN03-7](https://user-images.githubusercontent.com/43376853/91665148-81fbb080-eb2e-11ea-8d72-b99715e0b2ca.png)  
  - 통계학의 Z-score 개념을 차용  
    ![](https://latex.codecogs.com/gif.latex?%5Cdpi%7B150%7D%20Z_i%20%3D%20%28N_i%5E%7Breal%7D-%5Cbar%7BN%7D_i%5E%7Brand%7D%29/std%28N_i%5E%7Brand%7D%29)  
    이 ![](https://latex.codecogs.com/gif.latex?%5Cdpi%7B100%7D%20Z_i)가 motif i의 Statistical Significance를 포착함.  
    ![GNN03-9](https://user-images.githubusercontent.com/43376853/91697124-8d40f180-ebab-11ea-8b4e-f7c24a601cf3.png)  

    
### Network Significance Profile (SP)  
![GNN03-8](https://user-images.githubusercontent.com/43376853/91665295-7e1c5e00-eb2f-11ea-9c3e-c54a7fe74005.png)  

- 이제 이까지, Network Motif의 정의에 대해 알아보면서, Induced Subgraph란 무엇인지, Recurrence란 무엇인지, Significance란 무엇인지에 대해 알아봄  
  Subgraph 파트에서, Network Significance Profile(SP)라는 개념을 통해, Significance를 어떻게 계산하는지를 알아보았는데,  
  다른 하나의 궁금증은 -> Random graph들은 어떻게 generate 해야 하는가? 좋은 Null model이란 무엇인가?  
  
### Configuration Model  
- Degree Sequence k_1, k_2, ..., k_N이 주어졌을 때, random graph generate해내는 방법 [개념 이해](https://en.wikipedia.org/wiki/Configuration_model)   
- 네트워크의 Null Model로서 유용  
- Configuration Model을 통해 만들어낸 Random Graph는,  
  
  - 노드(Nodes)의 개수  
  - 간선(Edges)의 개수   
  - Degree Distribution  
  
  세 가지 모두 Real Graph와 같아진다.  

- Configuration Model을 generation 하는 방법?  

  ```  
  1. Spoke!  
  2. Switching!  
  ```  
  
  #### 1.Spoke  
  ![GNN03-10](https://user-images.githubusercontent.com/43376853/91697718-8b2b6280-ebac-11ea-98e0-d382a2aad316.png)  
  - 4개의 노드가 있다고 가정했을 때, Real 그래프에서의 각 노드들은 각자의 Spoke들을 지니고 있음  
  - 먼저 노드 A에서부터 시작해, spoke의 수를 유지하면서 확장해나감.  
  - Node B가 이상함을 느낄 수 있는데 (분명 Real 그래프에서의 spoke수는 4였는데, random graph에서는 3개가 나옴) 이런 bad event는 'Exponentially rare'  
  - 초록색 글자로 언급되었듯, Spoke를 이용한 Configuration Model generation은 'Double Edges'나 'Self-loops'는 고려하지 못한다는 단점이 있음.  
  
  #### 2.Switching  
  - Spoke에 비해서 훨씬 expensive한 방법이지만, 원 그래프에서의 Degree Sequence를 완벽하게 유지함.  
  - Real Graph에서 시작해서, Edge들을 충분히 Cross시켜준다.  
  - 그럼 결과는 'Randomly rewired graph (with same node degrees)'  
    ![GNN03-11](https://user-images.githubusercontent.com/43376853/91698418-aa76bf80-ebad-11ea-84ea-a302f893106b.png)  
    - 여기서 Q: Repeat times.  
    - converge: converge to a uniform sample  
    
- Spoke나 Switching을 통해서 random graph를 generate하면, (위에서 본 적 있던 그래프가 다시 등장) 비로소 `Network Significance Profile`을 얻어낼 수 있게 됨  
  ![GNN03-12](https://user-images.githubusercontent.com/43376853/91698671-0d685680-ebae-11ea-91dc-72b33662e1e7.png)  

  ![GNN03-13](https://user-images.githubusercontent.com/43376853/91699110-c169e180-ebae-11ea-87c6-a748a7429cb4.png)

  - 물론, Motif에도 다양한 변형(Variation)들이 있음.  
    ![GNN03-14](https://user-images.githubusercontent.com/43376853/91699352-24f40f00-ebaf-11ea-8f04-f257bddf0bd7.png)  
    
---  

## Graphlets: Node feature vectors  
- Graphlet: Network Motif의 Extension으로 이해하면 편함  
  - Network Motif: '전체' 네트워크를 characterize하는 데에 사용  
  - Graphlets: 주어진 '__노드__'를 characterize하는 데에 사용    
  
- Graphlets  
  ![GNN03-15](https://user-images.githubusercontent.com/43376853/91699727-b2376380-ebaf-11ea-9f06-a3965ebaaa47.png)  
  - 그래프의 크기↑ → graphlet의 갯수↑   
  - 가령, G1과 G2는 노드의 개수는 같지만, non-isomorphic position에 있음.  
  
  - 일반적으로 그래프에서 써왔던 'Degree'라는 개념  
    -> Graphlets에서도 물론 적용 가능.  
    -> Graphlets에서는 `Graphlet Degree Vector`라는 개념을 도입  
    
  - `Automorphism orbit`: 부분그래프의 대칭성을 고려 (즉, Isomorphism between the same object)  
  - `Graphlet Degree Vector`: 각 orbit position에서 노드의 빈도를 기록한 벡터  
    ![GNN03-16](https://user-images.githubusercontent.com/43376853/91701401-34c12280-ebb2-11ea-9f5d-e70f26b07711.png)  
    - Graphlet Degree Vector를 통해 노드의 국소적인 네트워크의 위상(local network topology)에 대한 measure를 제공  
    
---  

## Finding Motifs and Graphlets  
- 그렇다면, Motif와 Graphlet을 어떻게 찾는가?  
  - Size가 k인 motifs / graphlets 를 찾는 게 목표라고 하자  
  - 두 가지 문제를 해결해야 함  
 
    ```  
    1. Enumerating  
    2. Counting  
    ```  
    - 1, 2를 위한 연구가 굉장히 활발.  
    
- 1. Enumerating  
  : Size-k 짜리의 모든 instance를 찾는다.  
- 2. Counting  
  : 모든 Instance들에 대해 Isomorphic instance들의 개수를 센다.  
  
- 특정 Subgraph가 그래프 내에 존재하는지 찾는 것은 Hard computational problem!  
  Motif size가 3~8일 때가 그나마 Feasible한 허용 범위.  
      
#### Enumerating & Counting을 위한 방법론  
- Exact subgraph enumeration (ESU) \[Wernicke 2006] <- 오늘 다룰 알고리즘  
- Kavosh \[Kashani et al. 2009]  
- Subgraph sampling \[Kashtan et al. 2004]  

##### Exact Subgraph Enumeration (ESU)  
- 두 가지 집합   
  ![GNN03-17](https://user-images.githubusercontent.com/43376853/91705716-4f969580-ebb8-11ea-8401-df41ade7ce95.png)  
  - V_subgraph: 특정 시점까지 만들어놓은 부분그래프  
  - V_extension: 그 Subgraph를 확장하는 데에 사용할 노드 후보군들의 집합  
  
- Idea  
  ![GNN03-18](https://user-images.githubusercontent.com/43376853/91705952-a69c6a80-ebb8-11ea-8c6d-cacb1e5c92df.png)
  
- Recursive Implementation!  
  - Depth k의 트리 구조아 유사하다. (`ESU-Tree`라고도 불림)  
  - Pseudo-code  
    ![GNN03-19](https://user-images.githubusercontent.com/43376853/91706297-2aeeed80-ebb9-11ea-95ad-140f9805b454.png)  





---  

### References  
[CS224W: Motifs and Structural Roles in Networks](http://web.stanford.edu/class/cs224w/slides/03-motifs.pdf)  


  
