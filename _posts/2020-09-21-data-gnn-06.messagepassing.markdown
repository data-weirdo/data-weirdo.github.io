---
layout: post
title:  "CS224W - 06.Message Passing and Node Classification"  
subtitle:   "GNN-06.message passing"
categories: data
tags: gnn
comments: true
---

- CS224W의 6주차 강의, Message Passing and Node Classification을 보고 정리한 글입니다.  
  [1. Message Passing and Node Classification](#message-passing-and-node-classification)  
  [2. Application of iterative classification framework](#application-of-iterative-classification-framework)  

---  

## Message Passing and Node Classification  
- 오늘의 메인 궁금증  
  : 어떤 네트워크가 주여졌을 때, 몇몇 노드들에는 label이 있다면, 그렇지 않은 node들에는 어떻게 label을 설정해줄 수 있을까?  
  - 'Semi-supervised` node classification  
    ![gnn06-1](https://user-images.githubusercontent.com/43376853/94362119-14727e00-00f4-11eb-941d-5be3b67d6259.png)  
    
### Collective classification  
- 위와 같이 네트워크 상의 모든 노드들에 label을 assign하는 태스크!  
- Intuition  
  : 네트워크 상에서는 분명 Correlation이 존재하고, 우리는 이 정보를 __Leverage__ 하면 된다!  
  
- Collective Classification의 세 가지 테크닉  

  ```  
  1. Relational classification  
  2. Iterative Classification  
  3. Belief Propagation  
  ```  
  
  #### Correlation?   
  - Correlation을 낳는 3가지 __Dependency__  
  
    - 1. Homophily  
      - 비슷한 성향을 지닌 사람들이 사회적인 connection을 형성한다.   
      - 유유상종  
      - ex. age, gender, organizational role, ...  
    - 2. Influence  
      - Social connection은 개인들에게 영향을 미친다.  
      - 이 강의에서 메인으로 다룰 대상  
    - 3. Confounding  
      - 외부적인 요인이 개인 및 social connection 모두에 영향을 미친다.  
    
      ![gnn06-2](https://user-images.githubusercontent.com/43376853/94362249-fd805b80-00f4-11eb-9244-c86d4aeb8311.png)  

    
- (처음의 궁금증으로 돌아와서,) 예를 들어, 다음과 같은 네트워크에서 Beige 색의 노드들에는 어떻게 label을 predict?  
  = 어떻게 네트워크 상에서 관찰되는 __Correlation을 Leverage__ 할 것인가?  
  ![gnn06-3](https://user-images.githubusercontent.com/43376853/94362358-a929ab80-00f5-11eb-9fe8-0d19d4dbbe1b.png)  
  (이 그림은 Binary Classification이지만, Multiple Classifier도 충분히 가능한 이야기)  
  
- Motivation  
  - 유사한 노드들은 Directly connected 되어 있거나, Close together 이거나!  
  - 네트워크 내에서 어떤 object O의 Classification Label은 다음 3가지에 의존할 것  
  
    ![gnn06-4](https://user-images.githubusercontent.com/43376853/94362438-353bd300-00f6-11eb-8421-d22d0090e4e2.png)  

- 위의 Task는 결국 다음과 같은 문제로 귀결될 수 있음.  
  - W: nxn (weighted) adjacency matrix  
  - Y: Label들의 벡터 ![](https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20Y%20%3D%20%5C%7B%20-1%2C%200%2C%201%20%5C%7D%5En)  
    - 1: + node  
    - -1: - node  
    - 0: unlabeld node  
  - 결국, 0인 노드들 중, 어떤 노드들이 1일지를 예측하라는 것.  
  
- 이 단순한 사고의 다양한 application 사례  
  - Document classification  
  - Part of speech tagging  
  - Link prediction  
  - Optical character recognition  
  - Image/3D data segmentation  
  - Entity resolution in sensor networks  
  - Spam and fraud detection  
  
### Collective Classification Overview  
- 마코프 가정  
  - 어떤 한 노드의 Label은 그 Neighbor 노드의 Label에 의존한다.  
    ![](https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20P%28Y_i%7Ci%29%20%3D%20P%28Y_i%20%7C%20N_i%29)  
    
- 3 Steps?  
  - Step1. Local Classifier  
    : 초기 label 부여  
  - Step2. Relational Classifier  
    : 노드들 간의 correlation을 capture!  
  - Step3. Collective Inference  
    : 네트워크를 통해 correlation을 propagate  
    
    ![gnn06-5](https://user-images.githubusercontent.com/43376853/94362861-1ab72900-00f9-11eb-84fc-8f60da2999a3.png)  
    
- Collective Classification을 위해 3가지 테크닉을 사용할 것이며,  
  이 3가지(Relational classifiers, Iterative Classification, Belief propagation) 모두 __Approximate__ inference다!  
  - 또한, 모두 Iterative algorithm  
  
### 1. Relational Classifier  
- 
  
  
  
  
