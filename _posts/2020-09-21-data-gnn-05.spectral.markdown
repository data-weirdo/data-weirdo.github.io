---
layout: post
title:  "CS224W - 05.Spectral Clustering"  
subtitle:   "GNN-05.spectral clustering"
categories: data
tags: gnn
comments: true
---

- CS224W의 5주차 강의, Spectral Clustering을 보고 정리한 글입니다.  
  [1. Spectral Clustering](#spectral-clustering)  
  [2. Motif-Based Spectral Clustering](#motif-based-spectral-clustering)  

---  

## Spectral Clustering  
- '어떻게 Spectral Method를 이용해서 Community Detection을 할 것인가?'  
  - Specral Method: Graph Adjacency Matrix의 Eigenvalue, Eigenvector를 계산하는 법 (선형대수)  
  
- 세 가지 Step  
  - ⅰ. Preprocessing  
    - 그래프를 Matrix representation으로 나타낸다.  
  - ⅱ. Decomposition  
    - Matrix로부터 Eigenvalue, Eigenvector를 계산해낸다.  
    - 각 점들을 하나 이상의 Eigenvector들에 근거해 Low-dimension 공간으로 Mapping!  
  - ⅲ. Grouping  
    - 새로운 Representation에 근거하여, 각 점들을 두개 이상의 클러스터에 Assign!  
    
- 결국 Spectral Clustering도 Graph Partitioning인데, Spectral Clustering 전에 보다 근본적인 문제에 대한 궁금증이 생김  
  - 그래프의 '좋은' Partition이란 무엇이지?  
  - 좋은 Partition을 '효율적으로' '확인(Identify)'할 수 있는 방법은 없을까?  
  
  - (첫번째 물음에 대해, 4강에서 'Modularity'를 떠올릴 수 있는데, 'Modularity'는  Null Model과 Physics의 view였다면,  
     이번 Chapter는 CS적인 최적화의 관점 → Approximation Guarantee와 얼마나 Network가 잘 working하는지에 대한 이야기를 하게 될 것)  
     
  ### '좋은' Partition이란?  
  - Group 내의 connection 수를 Maximize, Group 간의 connection 수는 Minimize하는 Partition  
  - 그렇다면, Group을 잘 '잘라야' 할텐데, 이에 'Graph Cuts'라는 개념 출현  
    ![gnn05-02](https://user-images.githubusercontent.com/43376853/93751340-e7c3ef80-fc37-11ea-80fb-77a90e508e26.png)  
    - `cut(A,B)`: 두 Sets를 얻기 위해 몇 개의 edges를 끊어야 하는가.  
    
    ![gnn05-01](https://user-images.githubusercontent.com/43376853/93751239-ba774180-fc37-11ea-89db-60f0c1921fc6.png)  
    
  - Objective Function을 'Edge Cut'에 대한 함수로 만든다.  
    - Criterion1. __Minimum-cut__  
      ![gnn05-03](https://user-images.githubusercontent.com/43376853/93751523-2fe31200-fc38-11ea-8902-476d664b484c.png)  
      - 하지만 이 Criterion은 Externel cluster connection에만 집중한 나머지, internal cluster connectivity를 고려하지는 못함 (ex. Degenerate Case)  
        ![gnn05-04](https://user-images.githubusercontent.com/43376853/93751698-77699e00-fc38-11ea-9a03-243f6edcb6ef.png)  
    - Criterion2. __Conductance__  
      - Criterion1의 문제를 해결  
      - 이 Criterion을 사용하면, 좀 더 Balanced한 Partition을 얻을 수 있다.  
      - `Φ(A,B)`: 각 그룹의 __Density__ 대비 그룹간의 connectivity  
        ![gnn05-05](https://user-images.githubusercontent.com/43376853/93752169-3756eb00-fc39-11ea-8cad-a2c9eb02592b.png)  

          - vol(A), vol(B) 즉 각 그룹의 Size가 비슷할수록 분모의 값이 커질 것. (→ Φ값이 작아짐)  
            (Conductance가 가능한 작기를 바라는 목적과 상통!)  
            
  ### '효율적으로' 좋은 Partition을 찾을 순 없을까?  
  - Best Conductance 찾기는 NP-hard Problem!  
  - (Guaranteed된) Approximation을 통해 해결하자.  
  
### Spectral Graph Partitioning  
- A: 무방향 그래프 G의 인접행렬 
- __x__ (= (x1, x2, ..., xn)): n개 노드들의 label 및 value를 담은 vector  

- A·__x__ : 각 노드들의 neighbor들의 labels sum  
  ![gnn05-06](https://user-images.githubusercontent.com/43376853/93753300-e647f680-fc3a-11ea-9e78-3a6618760250.png)  
  
  - A·__x__의 jth component: j번째 노드의 neighbor들의 x 값들의 합!  
  
#### Spectral Graph Theory  
- Adjacency matrix A를 다음과 같이 Decompose할 수 있다.  
  ![gnn05-07](https://user-images.githubusercontent.com/43376853/93757941-89503e80-fc42-11ea-862e-c0ecd8216b5a.png)  
  
  - Eigenvalue들을 오름차순으로 정리했을 때, 그에 대해 상응하는 Eigenvector들을 `Spectrum`이라고 하고  
    그래프 G를 나타내는 함수의 `Spectrum`을 분석하는 것이 __Spectral Graph Theory__  
    
  - Case1: d-Regular Graph  
    - 그래프 G의 모든 노드들의 Degree가 d라면?  
      - x = (1, 1, ..., 1), λ=d  
        (d가 A의 eigenvalue들 중 가장 큰 값)  
  
  - Case2: Graph on 2-Components  
    - 그래프 G가 연결되어있지 않고, d-regular인 두 개의 component로 나누어져 있다면?  
      ![gnn05-08](https://user-images.githubusercontent.com/43376853/93758524-928ddb00-fc43-11ea-8c2c-5a554290b1ef.png)  
      
    - 직관적으로, connected d-regular graph의 eigenvector는 (1,1, ..., 1) 일 것.  
    - Eigenvector들 간에는 orthogonal하기 때문에, eigenvector들의 component들은 양, 음수 모두를 갖게 될 것.  
    - 두번째로 큰 Eigenvalue에 대응하는 Eigenvector에 대해, 양수인 node들은 같은 group으로, 음수인 node들을 또 다른 하나의 group으로 묶는다!  
    
### Matrix Representations  
- Anxn: Adjacency Matrix    
  ![gnn05-09](https://user-images.githubusercontent.com/43376853/93759904-0af59b80-fc46-11ea-83dc-3181296ed516.png)  
  - 대칭행렬  
  - n개의 real eigenvalues  
  - eigenvector의 component들 역시 실수값을 가지며, eigenvector들 간에는 orthogonal   

- Dnxn: Degree Matrix  
  ![gnn05-10](https://user-images.githubusercontent.com/43376853/93760009-35475900-fc46-11ea-9834-00dfad1dd287.png)  
  
- Lnxn: __Laplacian Matrix__  
  - L = D-A  
    ![gnn05-11](https://user-images.githubusercontent.com/43376853/93760157-70498c80-fc46-11ea-8a67-e8ef8aa22fb9.png)  
  - Laplacian Matrix의 Rowsum = 0  
  - 생각해볼 수 있는 Trivial Eigenpair: Eigenvector (1,1,...,1) with eigenvalue 0  
  
  - Eigenvalue: 0이상의 실수  
  - Eigenvector: 모두 실수값들을 가짐  
  
  - Laplacian Matrix가 지니는 성질  
    ![gnn05-12](https://user-images.githubusercontent.com/43376853/93760399-e6e68a00-fc46-11ea-95c0-0f67ffe4da69.png)  
    
    - Laplacian Matrix로 무엇을 할 수 있나?  
      -> Laplacian Matrix의 2nd Largest Eigenvalue는, 그래프 내 node들을 partition할 때, node들간의 거리 합의 최소값!  
        (이 말인즉슨, 2nd Largest Eigenvalue에 대응하는 2nd Eigenvector들을 바탕으로 0보다 큰 값을 하나의 그룹으로, 0보다 작은 값을 다른 한 그룹으로 partition 할 때가 최상의 partition이 된다는 것)  
         
      - 이는, 다음의 사실을 이용한 것.  
        ![gnn05-13](https://user-images.githubusercontent.com/43376853/93761349-9d973a00-fc48-11ea-9d91-d083c88a62a6.png)  
        
        M의 자리에 L(Laplacian Matrix)을 넣으면, 이 식은 다음과 같이 변형됨  
        ![gnn05-14](https://user-images.githubusercontent.com/43376853/93761462-c91a2480-fc48-11ea-85ea-92b21b10e5a7.png)  
        - eigenvector의 성질에 따르면 분모는 1이 되고, 이는 곧 분자를 최소화하겠다는 것과 동치.  
        - 2nd eigenvector에서 0보다 작은값은 왼쪽으로, 큰 값은 오른쪽으로 모아서 cross edge들을 최대한 줄이는 optimize problem이며,  
          이 optimize solution은 λ2  
          ![gnn05-15](https://user-images.githubusercontent.com/43376853/93761632-10081a00-fc49-11ea-8b55-93f694de1767.png)  
 

---  
- 다시 Optimal cut을 찾는 문제로 돌아와서,  
  - Fiedler는 1973년에 다음과 같은 방법을 제시  
    ![gnn05-16](https://user-images.githubusercontent.com/43376853/93774720-82cec080-fc5c-11ea-9f61-008ee5b4ae4c.png)  
    - 바로 앞의 사고와 굉장히 유사한 사고  
  - Rayleigh Theorem (또다른 Classical Theory)  
    ![gnn05-17](https://user-images.githubusercontent.com/43376853/93775304-35068800-fc5d-11ea-8b7f-fb8622f30786.png)  
    
    - 이런 사고들이 왜 중요한가?  
      ∵ 이런 종류의 Graph Laplacian의 Spectral Clustering은 Near Optimal Solution을 주기 때문.  

  
