---
layout: post
title:  "CS224W - 08.Graph Neural Networks"  
subtitle:   "GNN-08.gnn"
categories: data
tags: gnn
comments: true
---

- CS224W의 8주차 강의, Graph Neural Networks를 보고 정리한 글입니다.  
  [1. Graph Neural Networks](#graph-neural-networks)  
  [2. Basics of Deep Learning for Graphs](#basics-of-deep-learning-for-graphs)  
  [3. Graph Convolutional Networks and GraphSAGE](#graph-convolutional-networks-and-graphsage)  
  [4. Graph Attention Networks](#graph-attention-networks)  
  [5. Example Application](#example-application)  

---  

## Graph Neural Networks  
- Node Embedding  
  - Intuition  
    : 'Input graph를 d-dimension의 embedding space로 mapping 시켰을 때, Original Network 상에서의 Similar한 두 노드들이, embedding space에서 가까이에 위치했으면 좋겠다.'  
    
  - 목표  
    : 'Embedding Space'에서의 similarity가 'Original Network'에서의 similarity를 잘 근사했으면 좋겠다!  
    - 이 때 이 'similarity'라는 것에 대해 정의해야 할 필요성이 생김  
      ![gnn08-01](https://user-images.githubusercontent.com/43376853/94647851-5259e700-032c-11eb-9f9e-b46561031ae3.png)  
      
  - Node Embedding의 두 가지 Components  
    1. Encoder: Node를 Low-dimensinal vector로 Mapping  
      ![](https://latex.codecogs.com/gif.latex?ENC%28v%29%20%3D%20%5Cmathbf%7Bz%7D_v)  
      - Chap7에서는 Shallow Encoder에 집중했음. (Using Embedding Lookup)  
        ![](https://user-images.githubusercontent.com/43376853/94418419-5961e780-01bc-11eb-954f-4b52343b5175.png)  
      - 하지만 Shallow Encoder에는 몇 가지 문제점이 존재  
      
        ---  
        1. 추정해야할 Parameter의 수  = 노드의 개수  
        2. 학습한 적이 없는 네트워크에 대해서는 모든 것을 다시 re-embed 해야.   
        3. Node features를 고려하지 않는다.  
        ---  
        
      - Chap8: Deep Encoder에 대한 소개가 될 것.  
        ![gnn08-02](https://user-images.githubusercontent.com/43376853/94648613-e0829d00-032d-11eb-8311-9598e4f7e382.png)  
        
        - 이 Deep Encoder는 어떤 node similarity function과도 결합될 수 있다.  
        - 아래의 Deep Graph Encoders라는 제목 하에 계속 이어서 서술!  

        
    2. Similarity Function: Input Network에서의 relationship이 어떻게 embedding space에서의 relationship으로 mapping 되는지에 대해 정의    
      ![](https://latex.codecogs.com/gif.latex?similarity%20%28u%2Cv%29%20%5Capprox%20%5Cmathbf%7Bz%7D_v%5ET%20%5Cmathbf%7Bz%7D_u)  
      
### Deep Graph Encoders  
- 아래의 그림처럼 그래프를 받고, Deep NN으로 보내서, 결국에는 어떤 Prediction task에 대해 사용할 수 있는 node embedding을 얻어내면 참 좋을텐데, 사실 이 과정은 굉장히 어려움  
  ![gnn08-03](https://user-images.githubusercontent.com/43376853/94649143-02305400-032f-11eb-89ca-2eb0bc36f3ac.png)  
- 왜냐하면, 현재 존재하는 ML/DL Toolbox는 simple data types에 특화되어 있기 때문에. (ex. 이미지, 텍스트)   
- 하지만 Graph는 Not simple  
  - 사이즈도 뒤죽박죽, 위상학적인 구조도 매우 복잡 (grid와 같은 어떤 공간적인 locality도 존재하지 않음.)  
  - 노드들 간의 순서라든지, reference point가 존재하지 않음.  
  - 종종 dynamic & multomodal feature들을 가지기도.  
  
  - 그래프는, 여타 다른 데이터들과 성격자체가 다르다고 할 수 있겠다.  
  
  - Graph를 Represent하기 위한 한 가지 Naive한 방법은, Adjacency matrix와 features를 함께 Join해서 이를 NN의 input으로 넣는 것.    
    ![gnn08-04](https://user-images.githubusercontent.com/43376853/94649546-d792cb00-032f-11eb-8a2b-030943aad03d.png)  
    
  - 그다지 좋은 idea는 아님  
    - Parameter의 수가 많다. 
      - 이 경우, 이미 첫번째 layer에서 Node의 개수인 5개보다 많은, 7개의 parameter를 사용 -> network를 깊게 만들수록 결과는 더 나빠질 것  
    - 다른 size의 그래프에는 not applicable  
      - 노드 6개짜리 graph에서는 working하지 x  
    - Node의 순서에 invariant하지 않다.  
      - 예를 들어, A B C D E 순서로 adjacency matrix를 정리했을 때와, D C A B E 로 adjacency matrix를 정리했을 때 이는 network 상에서의 input이 달라지는 것이고, 얻게될 결과도 달라진다.  
      
---  
 
## Basics of Deep Learning for Graphs  
- 갖고 있는 정보에 대한 가정  
  - V: Vertex set  
  - A: Adjacency Matrix  
  - X: Node features  
    ![](https://latex.codecogs.com/gif.latex?%5Cmathit%7BX%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20%7CV%7C%7D)  
    
### Graph Convolutional Networks  
![gnn08-05](https://user-images.githubusercontent.com/43376853/94651006-b2538c00-0332-11eb-8848-da4662b64315.png)  
- 어떤 node가 주어지면, 그 노드에 대한 prediction을 진행하고 싶을 때,  
  1. 먼저, 무엇이 Computational graph가 되어야할지를 결정하고  
  2. (prediction task를 위해) 이 computational graph를 사용해서 neighbors 혹은 neighbors의 neighbors들로부터 Propagate & Aggregate Info!  
  
  - 오, 여기서 'Neighors를 Aggregate한다는 것이 무엇이지?'  
  
#### Aggregate Neighbors  
- Key Idea: Local Network Neighborhoods에 근거해서 node embedding을 generate하겠다.  
  ![gnn08-06](https://user-images.githubusercontent.com/43376853/94651757-eed3b780-0333-11eb-86df-8b4801598feb.png)  
  - 단 Graph 도메인에서는 4,5 Layer 이상으로 잘 가지 않는다  
    ∵ MSN 예시에서 보았듯, 그래프 Domain에서는 Depth 6 정도면 그래프 내의 거의 모든 노드들을 방문할 수 있음.  
      (이런 의미에서 그래프 도메인에서는, Computer Vision에서 Layer를 깊게 쌓는 것과, Depth에 대한 관점 차이가 확연)   
      
- Intuition1  
  - 노드들은 주변 neighbor들로부터 NN을 사용하여 정보를 aggregate한다.  
    (단, 이 aggregation은 order invariant할 것)  
    ![gnn08-07](https://user-images.githubusercontent.com/43376853/94652158-8933fb00-0334-11eb-9ab0-efcdb1b1684e.png)  
    
- Intuition2  
  - Network neighborhood들이 `computation graph`를 정의한다.  
    (모든 노드들은 자기 자신의 NN 아키텍쳐를 갖고 있으며, 각자의 neighborhood에 근거하여 computation graph를 정의)  
    ![gnn08-08](https://user-images.githubusercontent.com/43376853/94652350-d912c200-0334-11eb-84cb-6b867e89d52a.png)  
    
- 모델은 어떤 Depth를 가져도 상관 없음. (Layers 수 ↑ → Deep model)  
  ![gnn08-09](https://user-images.githubusercontent.com/43376853/94653016-dc5a7d80-0335-11eb-8401-d7ec894fdb27.png)  
  
#### Neighboor Aggregation  
- 도대체 네모박스에는 어떤 것이 들어있을까?  
- Basic Approach:   
  1. Neighbors로 부터의 message를 average  
    (이론적으로는 Summation이 가장 Powerful하기는 하며, 합이든 평균이든 둘 다 Order Invariant)  
  2. NN 적용  
  ![gnn08-10](https://user-images.githubusercontent.com/43376853/94653235-378c7000-0336-11eb-81be-c4e15eb15af9.png)  
  
- 수식적인 이해  
  



  
